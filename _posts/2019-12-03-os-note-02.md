---
layout: post
title: "Modern Operating System - Process & Thread"
date: 2019-12-03 20:55
categories: note os
keywords: process thread
---





The core concept of the operating system is **process**: This is an abstraction of a **running program**...





#### 1. Process
##### Introduction
- program:
  - instruction sequence, embodying an algorithm
  - sequential
- **sequential** environment
  - there is only one program running, which owns all resources of system and not impacted by environment

features of a sequential program:
- `sequential`
  - execute operation one by one
- `closed`
  - state of resources can only changed by this program
- `reproducibility`
  - sequential + closed => **reproducibility**

program **concurrent** execution:
- target:
  - improve resource utilization, and thus system efficiency
- features
  - `discontinuity`
  - lost of `closure`
  - `non-reproducible`

Let's see the difference of `concurrency` and `parallel`
- parallel
  - both things are **active** at the same time
  - e.g. super-scalar design in CPU
- concurrency
  - only one thing is **active** at a time
  - e.g. multiple programs in `time-sharing system`

![parallel vs concurrency](https://github.com/eeux/blog-pictures/blob/master/2019/12/parallel-vs-concurrency.png?raw=true)

##### 1.1 process model
Why introduced?
- enable programs to execute correctly and concurrency
- describe and control concurrently executed programs

Let's see the concept of process:
- definition:
  - A process is a program runs on data set. It is an **independent unit** of the system for resource allocation and scheduling.
  - That is, a process is a **running program**, including program counter(PC), registers and the current value of variables.

- main idea:
  - process is some type of **activity** that has inputs, outputs and states.
  - in time-sharing system, a single CPU is shared by several processes. It uses some `scheduling algorithm` to decide when to stop one process and to serve other processes.

- process vs program
  
  | process | program |
  | ------- | ------- |
  | dynamic | static |
  | executing process | code set |
  | temporary | permanent |
  | has a certain life time | can be saved permanently |
  | program + data + process control block  | code |
  | can create other process | can't create new program |

##### 1.2. creation of process
cause of process creation:
- system initialization
- the current running process executes a system call that creates the process
- user request to create a new process
- initialization of a batch system

The system use a `process creation primitives` to create process, whose main work is the **creation of PCB**.
1. apply for free PCB
2. allocating resource for new process
3. initialize the PCB
4. insert new process into ready queue

![process-creation-flow](https://github.com/eeux/blog-pictures/blob/master/2019/12/process-creation-flow.png?raw=true)

##### 1.3 termination of process
- task finished normally or abnormally
- use `process termination primitives` to terminate
- it's main task is `recycling PCB`

**cause** of termination:
- process exited normally
- abnormal termination
  - no memory
  - out of range
  - protection error
  - arithmetic error
  - I/O failed
  - invalid instruction
  - privileged instruction
  - data misuse
- outside intervention
  - operator or operating system
  - request from parent process
  - parent process terminated

**procedure** of termination:
1. search for corresponding PCB
2. terminate the process and all child process
3. release resource
4. recycle PCB

##### 1.4 Linux task_struct
task_struct is a complex struct, which takes up 1000+ bytes(include/linux/sched.h). It mainly covers:
1. state and flags of process
   ```c
   volatile long state; /* -1 unrunnable, 0 runnable, >0 stopped: */
   unsigned long flags;
   ```
2. identifier
   ```c
   int pid; // process id
   unsigned short uid, gid; // user id, group id
   unsigned short euid, egid;
   unsigned short suid, sgid;
   unsigned short fuid, fgid; // file
   ```
3. family
   ```c
   struct task_struct *p_opptr;
   struct task_struct *p_pptr; // parent
   struct task_struct *p_cptr; // child
   struct task_struct *p_ysptr;
   struct task_struct *p_osptr;
   ```
3. link relationship
   ```c
   struct task_struct *next_task;
   struct task_struct *prev_task;
   struct task_struct *next_run;
   struct task_struct *prev_run;
   ```
4. scheduling information
   ```c
   long counter; // time slice
   long nice; // priority
   unsigned long rt_priority; // real-time priority
   unsigned long policy; // scheduling policy
   ```
5. time
   ```c
   long start_time; // creation time
   long utime; // user state
   long stime; // kernel state
   long cutime; // child user time
   long cstime; // child kernel time
   unsigned long timeout; // process application delay
   ```
6. virtual memory information
   ```c
   struct mm_struct *mm;
   struct desc_struct *ldt; // local description table
   unsigned long saved_kernel_stack;
   unsigned long kernel_stack_page;
   ```
7. file information
   ```c
   struct fs_struct *fs; /* file system information */
   struct files_struct *files; /* Open file information */
   ```
8.  information about `inter-process communication`(IPC)
    ```c
    /* Signal handlers */
    struct signal_struct *signal; 
    struct signal_struct *sighand; 
    sigset_t blocked; // mask of block signal
    struct signal_struct *sig; // signal process table
    int exit_signal;
    struct sem_undo *semundo; // semaphores to release
    struct sem_queue *semsleeping; // 
    ```
9.  other information
    ```c
    int errno; // error code of system call
    long debugreg[8]; // registers for debug
    char comm[16]; // received signal
    ```

##### 1.5 status of process
- ready
  - just need CPU to run
- running
  - process has owned CPU, whose program is running in CPU.
- blocked
  - temporary unable to continue due to some event(e.g. I/O request)
  - can only compete for CPU after the event is **complete**

![process status switch](https://github.com/eeux/blog-pictures/blob/master/2019/12/process-status-switch.png?raw=true)


##### 1.6 implementation of process
brief introduction first:
- **context**: the environment in which the process runs.
  - for x86 CPU, context of task including **program counter**, **stack pointer**, **general register**.
- **context switching**: an event occurs when control of the CPU is transferred from a running process to another **ready** process. The current running process becomes ready(or blocked), and another selected ready process becomes current running program. It includes:
  1. **saving** running environment of current running process
  2. **restoring** the running environment of process to be run

Process Control Block (`PCB`)
- a data structure specially set for process management.
- it describes the current situation of the process and all the information that controls the running of the process.
- process and PCB is **one-to-one correspondence**.
- it makes a program that cannot run in a multiprogramming environment a basic unit that can run independently

information in `PCB`:
- process identifier (`PID`)
  - internal identifier: numbers, generally used by system
  - external identifier: characters & numbers, provided by creator, generally used by users
  - processor status: consist of values in a variety of registers, used for scene saving and restoring when switching running tasks.
    - general registers
    - instruction registers
    - program status word (`PSW`)
    - user stack pointer
  - process scheduling information
    - process status
    - process priority
    - use-time and wait-time of CPU
    - blocking cause
  - process control information
    - address of program and data
    - process synchronization and communication information
    - list of resources
    - process queue pointer

![single-blocking-queue](https://github.com/eeux/blog-pictures/blob/master/2019/12/single-blocking-queue.png?raw=true)

![multi-blocking-queue](https://github.com/eeux/blog-pictures/blob/master/2019/12/multi-blocking-queue.png?raw=true)

organization of `PCB`ï¼š
- Generally, there are many `PCB`s, system must use suitable method to manage them. Common ways are `linking` and `indexing`.
- `PCB table`:
  - system organizes all `PCB` together and stores then in a fixed area of memory, which forms `PCB table`.
  - the size of `PCB table` determines the maximum number of simultaneous process int the system, which is called `system concurrency`.

![organize-pcb-linking](https://github.com/eeux/blog-pictures/blob/master/2019/12/organize-pcb-linking.png?raw=true)

![organize-pcb-indexing](https://github.com/eeux/blog-pictures/blob/master/2019/12/organize-pcb-indexing.png?raw=true)

`composition` of the process:
- Process Control Block: the only sign that the process exists
- program: describes function to be done
- data
- workspace: dynamic area(Stack area) for `parameter passing` and `system calling`


#### 2. Thread
##### thread model
process has two basic attributes:
- process is a basic unit of ownable resources
- process is a basic unit that can be independently scheduled and dispatched

these attributes enable concurrency execution of processes.

for concurrency of processes, system must finish:
- create process: allocate all necessary resources, except processor.
- repeal process: recycle resources possessed by process, and then repeal PCB.
- process switching: keep CPU environment of current process and set up a new one for newly selected process.

**Why thread?**
- concurrent programming in process units is not efficient
  - expensive time and space
    - schedule frequently
    - take up big space and memory resource
  - process communication is expensive
  - **large granularity** of inter-process concurrency

introduce of thread:
- the target of importing process is to make multiple program execute concurrently, which improves resource utilization and system throughout
- the target of importing thread is to reduce the expense caused by program concurrent execution

  | process items | thread items |
  | ------------- | ------------ |
  | address space | program counter |
  | global variables | registers |
  | open files | stack |
  | child processes | state |
  | pending alarms  | |
  | signals and signal handlers | |
  | accounting information | |

**use of thread**
- web server
  - dispatcher thread
  - worker thread

**thread vs. process**
- scheduling
- concurrency
- resource ownership
- system overhead

##### user level
- thread is invisible for kernel
- process level blocking

props:
- thread switching does not call the kernel
- scheduling is specified by application that we can choose best scheduling algorithm
- cross-platform (requires thread library)

cons:


##### kernel level

##### mixed

#### 3. IPC (inter-process communication)

##### software method
**1. lock variable**
```c
while (lock != 0);
lock = 1
critical_region();
lock = 0;
```

**2. spin lock**
cons: it's not a good idea if one process is quite slower than the other one;
```c
/* process P */
while (TRUE) {
    while (turn != 0);
    critical_region();
    turn = 1;
    noncritical_region();
}

/* process Q */
while (TRUE) {
    while (turn != 1);
    critical_region();
    turn = 0;
    noncritical_region();
}
```

**3. Dekker algorithm**
```c
pturn = false;
qturn = false;
turn = 1; /* or 2 */
/* process P */
while (true)
{
    pturn = true;
    while (qturn) {
      if (turn == 2) {
        pturn = false;
        while (turn == 2);
        pturn = true;
      }
    }

    critical_region();

    turn = 2;
    pturn = false;
}

/* process Q */
while (true)
{
    qturn = true;
    while (pturn) {
      if (turn == 1) {
          qturn = false;
          while (turn == 1);
          qturn = true;
      }
    }

    critical_region();

    turn = 1;
    qturn = false;
}
```

**4. Peterson**
```c
#define FALSE 0
#define TRUE 1
#define N 2
int turn;
int interested[N];

void enter_region(int pid)
{
    int other = 1 - pid;
    interested[pid] = TRUE;
    turn = pid;
    while (turn == pid && interested[other]);
}

void leave_region(int pid)
{
    interested[pid] = FALSE;
}
```

##### hardware method
1. masking interrupts
- idea
  - prevent process scheduling int critical region
  - ensure the integrity of operation in critical region
- analyse
  - dangerous for user to control system interrupts
  - doesn't work for system with multiple CPUs

    ```c
    clock_INT();
    critical_region();
    open_INT();
    ```
2. **TSL** (test and set lock)
  
    use hardware to implements `lock variable mechanism` (lock `memory bus`)
    ```asm
    TSL RX, LOCK
    ```
    and we can do like this:
    ```asm
    enter_region:
        TSL REGISTER, LOCK
        CMP REGISTER, #0
        JNE enter_region
        RET

    leave_region:
        MOVE LOCK, #0
        RET
    ```

---

`busy waiting` Model:
props:
- easy to understand

cons:
- not universal
- wastes CPU resources
- priority inversion problem
  - process `H` and `L`, prio(`H`) > prio(`L`)
  - `L` enters critical region first
  - `H` begins to `busy waiting`, but `L` can't be scheduled (with lower priority) and thus can't leave critical region!

##### sleep & wakeup
- use system call `Atomic Action` to alter status of process
- block process which can't enter critical region and wakeup them once meet the conditions
- can overcome resource wasting caused by `busy waiting`
- moreover, can achieve both `synchronization and mutex`

There are three method to realize this:

**1. simple sleeping - wakeup**
Lets see a classic problem -- `producer & consumer` or `bounded buffer` first:
- a bounded buffer used for storing stuffs
- `producer` puts stuff in buffer when it's not full
- `consumer` gets stuff from buffer when it's not empty

```c
#define N 100
int count = 0;

void producer()
{
    int item;
    while (TRUE) {
        item = produce_item();
        if (count == N) {
            sleep();
        }
        insert_item();
        count++;
        if (count == 1) {
            wakeup(consumer);
        }
    }
}

void consumer()
{
    int item;
    while (TRUE) {
        if (count == 0) {
            /*
            if CPU schedules here, consumer miss the chance to be waked up;
            producer will produce item continuously until the buffer is full.
            */
            sleep();
        }
        item = remove_item();
        count--;
        if (count == N - 1) {
            wakeup(producer);
        }
        consume_item(item);
    }
}
```

> Critical situation

- count is not constrained, which forms a `race condition`

**2. semaphore mechanism**
idea:
- introduce a new data struct: `semaphore`
- with semaphore, we can provide more complex atomic operations
- solve potential race conditions basically
- can be extend to general situations easily, which applying to mutex and synchronization

Let's see the data struct first:
```c
struct semaphore
{
    int value;
    /* resource usage situation:
      > 0: available resources number;
      = 0: all resource has assigned, and no process waiting for resources;
      < 0: all resource has assigned, and the absolute value stands for
          the number of blocked processed waiting for the resource.
    */
    PCB *queue; /* waiting queue */
}
```

Despite of `initialization` of semaphore, we can only access it by `P` and `V` operation.
- `P(s)`: decrease semaphore `s` by 1, if the result is less than 0, all process calling P(s) will be blocked.
- `V(s)`: increase semaphore `s` by 1, if the result is not greater than 0, then wakeup a process blocked by this semaphore.

```c
down(semaphore *s)
{
    s->value = s->value - 1;
    if (s->value < 0) {
        block(s->queue);
    }
}

up(semaphore *s)
{
    s->value = s->value + 1;
    if (s->value <= 0) {
        wakeup(s->queue); /* just wakeup one process */
    }
}
```

Now we can use semaphore to solve the `producer & consumer` problem:

here, both producer and consumer can be more than 1.
Therefore, we need three semaphores: `mutex`, `empty` and `full`.
```c
#define N 100
typedef int semaphore;
semaphore mutex = 1;
semaphore empty = N;
semaphore full = 0;

void producer(void)
{
    int item;
    while (TRUE) {
        item = produce_item();
        down(&empty);
        down(&mutex);

        insert_item();

        up(&mutex);
        up(&full);
    }
}

void consumer(void)
{
    int item;
    while (TRUE) {
        down(&full);
        down(&mutex);

        item = remove_item();

        up(&mutex);
        up(&empty);
        consume_item(item);
    }
}
```

we can come to conclusions:
- for `mutex`: `P` and `V` appears in pair, often initialized to 1.
- for `synchronization`, `P` and `V` may not appear in pair
- `mutex` is always next to `critical region`
**3. monitor**

idea:
- a independent module which implements procedures, variables and data structures
- every time, there is only one process in monitor at most
- achieve mutex among processes by supported by compiler

props:
- achieve automatization of mutex among processes
cons:
- depends on compiler

see the `producer & consumer` problem again :tada::
```c++
Monitor PC
{
    product buffer[K];
    Condition full, empty;
    static int in = 0, out = 0, count = 0;

    public void put(product x)
    {
        if (count == K) {
           WaitC(full);
        }
        buffer[in] = x;
        in = (in + 1) % K;
        count ++;
        SignalC(empty);
    }

    public void get(product *x)
    {
        if (count == 0) {
            WaitC(empty);
        }
        *x = buffer[out];
        out = (out + 1) % K;
        count --;
        SignalC(full);
    }
}
```

#### 4. Classic IPC problems
##### Dining philosophers problem
- mutex: one fork can be taken up by one philosopher at a time
- synchronization: philosopher can't eat until he owns 2 forks
- special situation
  - `dead lock`: every philosopher takes 1 fork
  - `degree of parallelism`: 5 forks allow 2 philosophers to eat simultaneously

```c
#define N 5
#define LEFT ((i + N - 1) % N)
#define RIGHT ((i + 1) % N)
#define THINKING 0
#define HUNGRY 1
#define EATING 2
typedef int semaphore;
int state[N];
semaphore mutex = 1;
semaphore s[N]; /* init is 0 */

void philosopher(int i)
{
  while (TRUE) {

  }
}

void take_forks(int i)
{
    down(&mutex);
    state[i] = HUNGRY;
    test(i);             /* try to get 2 forks */
    up(&mutex);
    down(&s[i]);         /* blocked if can't get required fork */
}

void put_forks(int i)
{
    down(&mutex);
    state[i] = THINKING;
    test(LEFT);
    test(RIGHT);
    up(&mutex);
}

void test(int i)
{
    if (state[i] == HUNGRY
        && state[LEFT] != EATING
        && state[RIGHT] != EATING) {
          state[i] = EATING;
          up(&s[i]);
    }
}
```

##### reader & writer
synchronization:
- reader entered buffer, writer must wait
- writer entered buffer, reader must wait
- `reader first`: once reader entered, subsequent reader can also enter
- `writer first`: once writer entered, subsequent reader can't enter

Solution with `reader first`:
```c
typedef int semaphore;
semaphore mutex = 1; /* rc access control */
semaphore db = 1;  /* database access control */
int rc = 0;  /* reader count */

void reader()
{
    while (TRUE) {
        down(&mutex);
        rc++;
        if (rc == 1) {
            down(&db);
        }
        up(&mutex);

        read_data();

        down(&mutex);
        rc--;
        if (rc == 0) {
            up(&db);
        }
        up(&mutex);

        /* non-critical region */
    }
}

void writer()
{
    while (TRUE) {
        down(&db);
        write_data();
        up(&db);
    }
}
```

Solution with `writer first`:
```c
semaphore rmutex, wmutex, write, concur;
rmutex.value = 1;
wmutex.value = 1;
write.value = 1;  /* RW, WW mutex */
concur.value = 1; /* for writer first */
int rcount = 0;
int wcount = 0;

void reader()
{
    while (TRUE) {
        down(&concur);
        down(&rmutex);
        rcount++;
        if (rcount == 1) {
            down(&write);
        }
        up(&rmutex);
        up(&concur);

        read_action();

        down(&rmutex);
        rcount--;
        if (rcount == 0) {
            up(&write); /* no reader now, writer can enter */
        }
        up(&rmutex);
    }
}

void writer()
{
    while (TRUE) {
        down(wmutex);
        wcount++;
        if (wcount == 1) {
            down(concur);
        }
        up(wmutex);

        down(write);
        write_action();
        up(write);

        down(wmutex);
        wcount--;
        if (wcount == 0) {
            up(concur); /* no writer now, reader can enter */
        }
        up(wmutex);
    }
}
```

##### sleeping barber
- mutex:
  - at most one customer in chair
  - waiting chairs are bounded buffer
- synchronization:
  - barber can't sleep when there is customer
  - customers have to wait when all barbers are cutting hairs

Solution in semaphores:
```c
#define CHAIRES N
semaphore customers, barbers, mutex;
customers.value = 0;
barbers.value = 0;
mutex.value = 1; /* for waiting access control */
int waiting = 0;

void Barber()
{
    while (TRUE) {
        down(&customers);
        down(&mutex);
        waiting--;
        up(&mutex);

        up(&barbers);
        cut_hair();
    }
}

void Customer()
{
    while (TRUE) {
        down(&mutex);
        if (waiting < CHAIRS) {
            waiting++;
            up(&customers);
            up(&mutex);

            down(&barbers);
            get_haircut();
        } else {
          up(&mutex); // just leave
        }
    }
}
```

#### 5. Schedule
- When?
- How?
- What?

methods:
- Preemptive scheduling: often used in time-sharing and most real-time systems.
- non-Preemptive scheduling

policy:
- priority principle
- shortest job first (SJF)
- time slice principle

> When?

- after forked a new process, we have to choose next process from parent process and child process
- running process finishes
- running process blocked by I/O request or semaphore
- I/O interruption happens

metric for process scheduling
- response time: the `interval` between when the process enters the ready queue and when the process **uses** the CPU
- turnaround time: the `interval` between when the process enters the ready queue and the end of the process
- CPU throughout: number of processes ended in unit time

principles:
- fairness
- validity: get the most use of your resources
- friendly: responsive
- fast: short turnaround time
- universality: high throughout

##### scheduling in batch system

1. first come first serve (FCFS)

    | process | arrive time | runtime | start time | finished time | turnaround time | weighted turnaround time |
    | :-----: | :---------: | :-----: | :--------: | :-----------: | :-------------: | :----------------------: |
    |       1 |           0 |      24 |          0 |            24 |              24 |                     1.00 |
    |       2 |           1 |       3 |         24 |            27 |              26 |                     8.67 |
    |       3 |           2 |       3 |         27 |            30 |              28 |                     9.33 |
    | avg     |             |         |            |               |              26 |                     6.33 |

2. short job first (SJF)

- can effectively reduce average waiting time
- which may cause `long jobs` are not scheduled for a long time
- does not schedule by `urgency` of processes
- difficult to estimate the `execution time` of a process

##### scheduling in interactive system
1. Round-Robin (RR)
- every process run within a fixed quantum, and then schedules the next process
- maintains a priority queue which read by `FIFO`
- special control: one process has to give up quantum if it's blocked or finished within it's quantum
- preemptive scheduling algorithm

the size of quantum is vital in scheduling system:
- too short: leads to process switching (context switching) frequently
- too long: increases response time

2.  Priority Scheduling
- assign priority for each process, process with higher priority first
- implement: maintains a priority queue, every get a process from front of queue
- special control: `static priority` & `dynamic priority`
    - static priority: decided when the process is created and constant during process lifetime, which is not precise enough. Often, static priority is decided by `process type`, requirement for resource, user requirement
    - dynamic priority: also decided when the process is created but is changeable. It's usually decided by CPU use time, waiting time of ready processes


- props: responsive, generic
- cons: hard rule

3. Feedback (FB)

   | process | arrive time | use time |
   | ------- | ----------- | -------- |
   | A       | 0           | 3        |
   | B       | 2           | 6        |
   | C       | 4           | 4        |
   | D       | 6           | 5        |
   | E       | 8           | 2        |

|      | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   | 11   | 12   | 13   | 14   | 15   | 16   | 17   | 18   | 19   | 20   |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| A    | #    | #    |      | #    |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
| B    |      |      | #    |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
| C    |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
| D    |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |
| E    |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |      |




#### 6. Conclusion

---
(:fire: updating...)
